---
title: "Temporal sequence learning via adaptation in biologically plausible spiking neural networks"
event: "Bernstein Conference 2014"
event_url: https://www.bernstein-network.de/en/bernstein-conference/past-conferences/2014

location: Göttingen, Germany
address:
  street: ""
  city: ""
  region: ""
  postcode: ""
  country: ""

summary: ""
abstract: "Ecologically relevant computations are carried out by a
complex interaction of adaptive dynamics, through a
variety of activity-dependent modifications of synaptic
and intrinsic neuronal properties. Such modifications
ought to be robust and reliable enough to endow neuro-
nal circuits with the ability to learn from and operate
upon complex, dynamic environmental variables.
On the lower levels of the cortical processing hierar-
chy, continuous data streams representing the environ-
ment are parsed, in order to isolate and attend to salient
and invariant features (’perceptual objects’), upon which
higher order cortical networks will operate, by flexibly
evaluating the dynamic relations between such structural
elements. The formation of stable representations of
spatial/spectral environmental features (stimulus selec-
tivity) along with the related ability to discriminate such
features and their combinations is known to be continu-
ously shaped and refined by synaptic plasticity mechan-
isms, and it has been recently demonstrated that
correlation-based inhibitory plasticity has an important
role to play in such computations.
However, in order to adequately process information,
neural circuits must not only develop stable internal
representations of perceptual objects, but also reflect
and represent the continuous unfolding structure of its
input, which is poised with intricate temporal dependen-
cies. Much less is currently known about the acquisition
of complex temporal relations between stimuli and the
(possibly specialized) role played by different adaptation
mechanisms involved in this process.
In this work, we study the properties of biologically
realistic networks of LIF neurons, with differentially
modulated, dynamic excitation and inhibition, combining
well established as well as more recent phenomenological
models of synaptic plasticity. Explicitly embedded or
entirely self-organized, input-specific neuronal assemblies
are driven by stimulus sequences that contain complex
temporal dependencies and signal propagation through-
out these assemblies is gated by transient disruptions of
E/I balance, in order to ‘prime’ the network to learn the
underlying transitional probabilities and input statistics
through targeted modifications of these ‘gating’ synapses.
We explore the representational properties developed by
these networks and the impact of the different plasticity
rules in shaping the network’s learning abilities while
maintaining stable global dynamics. Furthermore, we
assess the network’s ability to extract complex temporal
dependency rules between sequence elements and to use
the acquired knowledge to make predictions about
upcoming sequence elements."

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2014-09-02"
date_end: ""
all_day: true

# Schedule page publish date (NOT talk date).
publishDate: "2018-05-05T00:00:00Z"

authors: 
  - admin
tags: []

# Is this a featured talk? (true/false)
featured: false

image:
  caption: ""
  focal_point: Right

links:
- icon: object-group
  icon_pack: fas
  name: Poster
  url: https://doi.org/10.6084/m9.figshare.3496673.v1
  
# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []

# Enable math on this page?
math: true
---


